@Book{BQ,
  editor = 	 "Press, W.H.; Teukolsky, S.A.; Vetterling, W.T.; Flannery, B.P.",
  title = 	 "Classification, subtype discovery, aNumerical Recipes: The Art of Scientific Computing (3rd Edition)",
  publisher = 	 "Cambridge University Press",
  year = 	 "2007",
  address =	 "New York"
}




% @Book{MachineLearningI,
%   editor = 	 "R. S. Michalski and J. G. Carbonell and T.
% 		  M. Mitchell",
%   title = 	 "Machine Learning: An Artificial Intelligence
% 		  Approach, Vol. I",
%   publisher = 	 "Tioga",
%   year = 	 "1983",
%   address =	 "Palo Alto, CA"
% }





@article{BART,
    author = "Chipman, Hugh A. and George, Edward I. and McCulloch, Robert E.",
    doi = "10.1214/09-AOAS285",
    fjournal = "The Annals of Applied Statistics",
    journal = "Ann. Appl. Stat.",
    month = "03",
    number = "1",
    pages = "266--298",
    publisher = "The Institute of Mathematical Statistics",
    title = "B{ART}: Bayesian additive regression trees",
    url = "https://doi.org/10.1214/09-AOAS285",
    volume = "4",
    year = "2010"
  pages =	 "266--298"
}


% @Article{Samuel59,
%   author = 	 "A. L. Samuel",
%   title = 	 "Some Studies in Machine Learning Using the Game of
% 		  Checkers",
%   journal =	 "IBM Journal of Research and Development",
%   year =	 "1959",
%   volume =	 "3",
%   number =	 "3",
%   pages =	 "211--229"
% }


@Article{CART,
  author = 	 "Hugh A. Chipman , Edward I. George & Robert E. McCulloch",
  title = 	 "Bayesian {CART} Model Search",
  journal =	 "Journal of the American Statistical Association",
  year =	 "1998",
  volume =	 "",
  number =	 "",
  pages =	 "935--948"
}


@Book{MH,
  editor = 	 "W. K. Hastings",
  title = 	 "Classification, subtype discovery, aNumerical Recipes: The Art of Scientific Computing (3rd Edition)",
  publisher = 	 " Oxford University Press on behalf of Biometrika Trust",
  year = 	 "2007",
  address =	 "New York"
}

% @Article{MC,
%   author = 	 "W. K. Hastings",
%   title = 	 "Monte Carlo Sampling Methods Using Markov Chains and Their Applications",
%   journal =	 "Biometrika",
%   year =	 "1970",
%   volume =	 "57",
%   number =	 "1",
%   pages =	 "97--109"
% }




@inproceedings{Genz,
    author = {Genz, Alan},
    title = {Testing Multidimensional Integration Routines},
    booktitle = {Proc. Of International Conference on Tools, Methods and Languages for Scientific and Engineering Computation},
    year = {1984},
    isbn = {0-444-87570-0},
    location = {Paris, France},
    pages = {81--94},
    numpages = {14},
    url = {http://dl.acm.org/citation.cfm?id=2837.2842},
    acmid = {2842},
    publisher = {Elsevier North-Holland, Inc.},
    address = {New York, NY, USA},
} 





% @misc{anonymous,
%   title= {Suppressed for Anonymity},
%   author= {Author, N. N.},
%   year= {2019}
% }


@Article{MARS,
    author = 	 "Jerome H Friedman",
    title = 	 "Multivariate adaptive regression splines",
    journal =	 "The annals of statistics",
    year =	 "1991",
    volume =	 "",
    number =	 "",
    pages =	 "1-67"
}

@Article{AMI,
    author = 	 "G Peter Lepage",
    title = 	 "A new algorithm for adaptive multidimensional integration",
    journal =	 "Journal of Computational
    Physics",
    year =	 "1978",
    volume =	 "27",
    number =	 "2",
    pages =	 "192-203"
}

@phdthesis{GPSQ,
    author = {Osborne, Michael A.},
    title =  {Bayesian Gaussian Processes for Sequential Prediction, Optimisation and Quadrature},
    school = {Oxford University},
    year =   {2010}
}

@book{Rasmussen:2005:GPM:1162254,
    author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
    title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
    year = {2005},
    isbn = {026218253X},
    publisher = {The MIT Press},
} 
[download]


@misc{network,
    author = "Naeem M,Asghar S",
    year = "",
    title = "KEGG Metabolic Reaction Network (Undirected) Data Set",
    school = "Centre of Research in Data Engineering Islamabad Pakistan
    url = "https://archive.ics.uci.edu/ml/datasets/KEGG+Metabolic+Reaction+Network+(Undirected)#",
    institution = "University of California, Irvine, School of Information and Computer Sciences" 
}

@misc{ACS,
    author = "US Census Bureau",
    year = "2017",
    title = "{2017 American Community Survey PUMS data for Wyoming}",
    school = ""
    url = "https://www.census.gov/programs-surveys/acs/data/pums.html",
    institution = "American Community Survey (ACS)" 
}



@InProceedings{rescallingGenz,
    author="Sch{\"u}rer, Rudolf",
    editor="Alexandrov, Vassil N.
    and Dongarra, Jack J.
    and Juliano, Benjoe A.
    and Renner, Ren{\'e} S.
    and Tan, C. J. Kenneth",
    title="Parallel High-Dimensional Integration: Quasi-{M}onte {C}arlo versus Adaptive Cubature Rules",
    booktitle="Computational Science --- ICCS 2001",
    year="2001",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="1262--1271",
    abstract="Parallel algorithms for the approximation of a multi-dimensional integral over an hyper-rectangular region are discussed. Algorithms based on quasi-Monte Carlo techniques are compared with adaptive algorithms, and scalable parallel versions of both algorithms are presented. Special care has been taken to point out the role of the cubature formulas the adaptive algorithms are based on, and different cubature formulas and their impact on the performance of the algorithm are evaluated. Tests are performed for the sequential and parallel algorithms using Genz's test function package.",
    isbn="978-3-540-45545-5"
}

@ARTICLE{7352306, 
author={B. Shahriari and K. Swersky and Z. Wang and R. P. Adams and N. de Freitas}, 
journal={Proceedings of the IEEE}, 
title={Taking the Human Out of the Loop: A Review of {B}ayesian Optimization}, 
year={2016}, 
volume={104}, 
number={1}, 
pages={148-175}, 
keywords={Bayes methods;Big Data;optimisation;storage allocation;Bayesian optimization;human productivity;product quality;storage architecture;large-scale heterogeneous computing;massive complex software system;Big data application;Big data;Bayes methods;Linear programming;Decision making;Design of experiments;Optimization;Genomes;Statistical analysis;decision making;design of experiments;optimization;response surface methodology;statistical learning;genomic medicine;Decision making;design of experiments;optimization;response surface methodology;statistical learning}, 
doi={10.1109/JPROC.2015.2494218}, 
ISSN={0018-9219}, 
month={Jan},}



@article{doi:10.1002/cjs.11156,
author = {Chipman, Hugh and Ranjan, Pritam and Wang, Weiwei},
title = {Sequential design for computer experiments with a flexible {B}ayesian additive model},
journal = {Canadian Journal of Statistics},
volume = {40},
number = {4},
pages = {663-678},
keywords = {Additive regression trees, expected improvement, global optimization, nonstationary simulators, tidal power model, MSC 2010: Primary 62L05, secondary 62G08},
doi = {10.1002/cjs.11156},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.11156},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cjs.11156},
abstract = {Abstract In computer experiments, a mathematical model implemented on a computer is used to represent complex physical phenomena. These models, known as computer simulators, enable experimental study of a virtual representation of the complex phenomena. Simulators can be thought of as complex functions that take many inputs and provide an output. Often these simulators are themselves expensive to compute, and may be approximated by “surrogate models” such as statistical regression models. In this paper we consider a new kind of surrogate model, a Bayesian ensemble of trees (Chipman, George, \& McCulloch, 2010), with the specific goal of learning enough about the simulator that a particular feature of the simulator can be estimated. We focus on identifying the simulator's global minimum. Utilizing the Bayesian version of the expected improvement criterion (Jones, Schonlau, \& Welch, 1998), we show that this ensemble is particularly effective when the simulator is ill-behaved, exhibiting nonstationarity or abrupt changes in the response. A number of illustrations of the approach are given, including a tidal power application. The Canadian Journal of Statistics 40: 663–678; 2012 © 2012 Statistical Society of Canada},
year = {2012}
}

@article{rockova2017posterior,
  title={Posterior concentration for {B}ayesian regression trees and their ensembles},
  author={Rockova, Veronika and van der Pas, Stephanie},
  journal={arXiv preprint arXiv:1708.08734},
  year={2017}
}

@ARTICLE{rockova2019theory,
       author = {{Rockova}, Veronika and {Saha}, Enakshi},
        title = "{On Theory for BART}",
      journal = {AISTATS 2019},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2019,
        month = Oct,
          eid = {arXiv:1810.00787},
archivePrefix = {arXiv},
       eprint = {1810.00787},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/\#abs/2018arXiv181000787R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

  @Manual{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2018},
    url = {https://www.R-project.org/},
  }
  
  @book{Press:2007:NRE:1403886,
 author = {Press, William H. and Teukolsky, Saul A. and Vetterling, William T. and Flannery, Brian P.},
 title = {Numerical Recipes 3rd Edition: The Art of Scientific Computing.},
 year = {2007},
 isbn = {0521880688, 9780521880688},
 edition = {3},
 publisher = {Cambridge University Press},
 pages = {397-410},
 address = {New York, NY, USA},
} 


@inproceedings{Rasmussen:2002:BMC:2968618.2968681,
 author = {Rasmussen, Carl Edward and Ghahramani, Zoubin},
 title = {Bayesian {M}onte {C}arlo},
 booktitle = {Proceedings of the 15th International Conference on Neural Information Processing Systems},
 series = {NIPS'02},
 year = {2002},
 pages = {505--512},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2968618.2968681},
 acmid = {2968681},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@article{10.2307/25464673,
 ISSN = {00905364},
 URL = {http://www.jstor.org/stable/25464673},
abstract = {We derive rates of contraction of posterior distributions on nonparametric or semiparametric models based on {G}aussian processes. The rate of contraction is shown to depend on the position of the true parameter relative to the reproducing kernel Hilbert space of the Gaussian process and the small ball probabilities of the Gaussian process. We determine these quantities for a range of examples of Gaussian priors and in several statistical settings. For instance, we consider the rate of contraction of the posterior distribution based on sampling from a smooth density model when the prior models the log density as a (fractionally integrated) Brownian motion. We also consider regression with Gaussian errors and smooth classification under a logistic or probit link function combined with various priors.},
 author = {A. W. van der Vaart and J. H. van Zanten},
 journal = {The Annals of Statistics},
 number = {3},
 pages = {1435--1463},
 publisher = {Institute of Mathematical Statistics},
 title = {Rates of Contraction of Posterior Distributions Based on Gaussian Process Priors},
 volume = {36},
 year = {2008}
}
@book{Durrett:2010:PTE:1869916,
 author = {Durrett, Rick},
 title = {Probability: Theory and Examples},
 year = {2010},
 isbn = {0521765390, 9780521765398},
 edition = {4th},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 


@article{doi:10.1080/02664760802684177,
author = { Gianluca   Baio  and  Marta   Blangiardo },
title = {Bayesian hierarchical model for the prediction of football results},
journal = {Journal of Applied Statistics},
volume = {37},
number = {2},
pages = {253-264},
year  = {2010},
publisher = {Taylor & Francis},
doi = {10.1080/02664760802684177},

URL = { 
        https://doi.org/10.1080/02664760802684177
    
},
eprint = { 
        https://doi.org/10.1080/02664760802684177
    
}

}

@article{doi:10.1146/annurev-statistics-010814-020133,
author = {Davison, A.C. and Huser, R.},
title = {Statistics of Extremes},
journal = {Annual Review of Statistics and Its Application},
volume = {2},
number = {1},
pages = {203-235},
year = {2015},
doi = {10.1146/annurev-statistics-010814-020133},

URL = { 
        https://doi.org/10.1146/annurev-statistics-010814-020133
    
},
eprint = { 
        https://doi.org/10.1146/annurev-statistics-010814-020133
    
}
,
    abstract = { Statistics of extremes concerns inference for rare events. Often the events have never yet been observed, and their probabilities must therefore be estimated by extrapolation of tail models fitted to available data. Because data concerning the event of interest may be very limited, efficient methods of inference play an important role. This article reviews this domain, emphasizing current research topics. We first sketch the classical theory of extremes for maxima and threshold exceedances of stationary series. We then review multivariate theory, distinguishing asymptotic independence and dependence models, followed by a description of models for spatial and spatiotemporal extreme events. Finally, we discuss inference and describe two applications. Animations illustrate some of the main ideas. }
}

@inproceedings{briol2015frank,
  title={Frank-{W}olfe {B}ayesian quadrature: Probabilistic integration with theoretical guarantees},
  author={Briol, Fran{\c{c}}ois-Xavier and Oates, Chris and Girolami, Mark and Osborne, Michael A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1162--1170},
  year={2015}
}

@article{dorie2018package,
  title={R Package ‘dbarts’},
  author={Dorie, Vincent and Chipman, Hugh and McCulloch, Robert and Dorie, Maintainer Vincent},
  url={https://cran.r-project.org/web/packages/dbarts/},
  year={2018}
}

@book{gelman2006data,
  title={Data analysis using regression and multilevel/hierarchical models},
  author={Gelman, Andrew and Hill, Jennifer},
  year={2006},
  publisher={Cambridge university press}
}


@misc{wolframalpha,
  title = {Wolfram Alpha: Computational Intelligence},
  howpublished = {\url{https://www.wolframalpha.com/}},
  note = {Accessed: 2018-01-23}
}
@article{linero2018bayesian,
  title={Bayesian regression tree ensembles that adapt to smoothness and sparsity},
  author={Linero, Antonio R and Yang, Yun},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={80},
  number={5},
  pages={1087--1110},
  year={2018},
  publisher={Wiley Online Library}
}
@inproceedings{gunter2014sampling,
  title={Sampling for inference in probabilistic models with fast Bayesian quadrature},
  author={Gunter, Tom and Osborne, Michael A and Garnett, Roman and Hennig, Philipp and Roberts, Stephen J},
  booktitle={Advances in neural information processing systems},
  pages={2789--2797},
  year={2014}
}
@article{oates2019bayesian,
  title={Bayesian probabilistic numerical methods in time-dependent state estimation for industrial hydrocyclone equipment},
  author={Oates, Chris J and Cockayne, Jon and Aykroyd, Robert G and Girolami, Mark},
  journal={Journal of the American Statistical Association},
  number={just-accepted},
  pages={1--27},
  year={2019},
  publisher={Taylor \& Francis}
}
@article{ohagan1991bayes,
  title={Bayes--hermite quadrature},
  author={O'Hagan, Anthony},
  journal={Journal of statistical planning and inference},
  volume={29},
  number={3},
  pages={245--260},
  year={1991},
  publisher={Elsevier}
}
